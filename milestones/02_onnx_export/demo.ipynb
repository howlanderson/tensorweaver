{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Export Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pytorch.org/tutorials//beginner/onnx/export_simple_model_to_onnx_tutorial.html#save-the-onnx-model-in-a-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorweaver netron==8.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorweaver as torch # OR import torch\n",
    "from tensorweaver.toy_datasets.get_celsius_fahrenheit_dataset import (\n",
    "    get_celsius_fahrenheit_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "x_array, y_array = get_celsius_fahrenheit_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 2234.7233454369148\n",
      "epoch 1000, loss 6.180777208148875\n",
      "epoch 2000, loss 0.848490979961047\n",
      "epoch 3000, loss 0.8151145690666656\n",
      "epoch 4000, loss 0.8149056558994958\n",
      "epoch 5000, loss 0.8149043482480652\n",
      "epoch 6000, loss 0.8149043400630761\n",
      "epoch 7000, loss 0.8149043400118421\n",
      "epoch 8000, loss 0.8149043400115227\n",
      "epoch 9000, loss 0.8149043400115212\n"
     ]
    }
   ],
   "source": [
    "# define our model, a simple linear regression model\n",
    "class LinearRegressionModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)  # One in and one out\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# create our model\n",
    "our_model = LinearRegressionModel()\n",
    "\n",
    "# convert the dataset to tensors\n",
    "x = torch.tensor(x_array)  # temperature in celsius\n",
    "y = torch.tensor(y_array)  # temperature in fahrenheit\n",
    "\n",
    "# define our loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(our_model.parameters(), lr=0.0015)\n",
    "\n",
    "# train our model\n",
    "loss_path = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    # Forward pass: Compute predicted y by passing\n",
    "    # x to the model\n",
    "    pred_y = our_model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(pred_y, y)\n",
    "\n",
    "    # Zero gradients, perform a backward pass,\n",
    "    # and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss_path.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export our trained model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = (torch.tensor(((0.0,), (100.0,))),)\n",
    "onnx_program = torch.onnx.export(our_model, example_inputs, \"model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display our exported ONNX model by using netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'model.onnx' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:8080\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x11fd57bd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netron\n",
    "address = netron.serve('model.onnx')\n",
    "netron.widget(address, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using onnxruntime to load and run our exported ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Sample input: [array([[  0.],\n",
      "       [100.]])]\n",
      "onnx runtime outputs:  [[ 31.87891188]\n",
      " [212.05132755]]\n",
      "expected outputs: 0 celsius -> 32 fahrenheit, 100 celsius -> 212 fahrenheit\n"
     ]
    }
   ],
   "source": [
    "%pip install -q onnxruntime\n",
    "\n",
    "import onnxruntime\n",
    "\n",
    "onnx_inputs = [tensor.numpy() for tensor in example_inputs]\n",
    "print(f\"Sample input: {onnx_inputs}\")\n",
    "\n",
    " # will solve wired errors on some machines: pthread_setaffinity_np\n",
    "session_options = onnxruntime.SessionOptions()\n",
    "session_options.intra_op_num_threads = 1\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"./model.onnx\",\n",
    "    providers=[\"CPUExecutionProvider\"],\n",
    "    sess_options=session_options\n",
    ")\n",
    "\n",
    "onnxruntime_input = {input_arg.name: input_value for input_arg, input_value in zip(ort_session.get_inputs(), onnx_inputs)}\n",
    "\n",
    "# ONNX Runtime returns a list of outputs\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)[0]\n",
    "\n",
    "print(\"onnx runtime outputs: \", onnxruntime_outputs)\n",
    "print(\"expected outputs: 0 celsius -> 32 fahrenheit, 100 celsius -> 212 fahrenheit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
